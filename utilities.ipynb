{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions for managing point cloud and skeleton files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from queue import Queue\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCD_to_OFF(input_path):\n",
    "    '''Convert .pcd point cloud files to ASCII .off-like format.'''\n",
    "    pcd_path = Path(input_path).expanduser().resolve()\n",
    "    pcd_name = str(pcd_path.stem)\n",
    "    output_path = pcd_path.with_suffix(\".off\") # by default, output saved to input directory\n",
    "    \n",
    "    pcd = o3d.io.read_point_cloud(str(pcd_path)) # read the pcd file\n",
    "    pts = np.asarray(pcd.points)\n",
    "    with open(str(output_path), 'w') as h:\n",
    "        h.write(\"OFF\\n\")\n",
    "        h.write(f\"{len(pcd.points)} 0 0\\n\")\n",
    "        for point in pts:\n",
    "            h.write(f\"{point[0]} {point[1]} {point[2]}\\n\")\n",
    "\n",
    "def PCD_to_PLY(input_path):\n",
    "    '''Convert .pcd point cloud files to ASCII .ply format.'''\n",
    "    pcd_path = Path(input_path).expanduser().resolve()\n",
    "    pcd_name = str(pcd_path.stem)\n",
    "    output_path = pcd_path.with_suffix(\".ply\") # by default, output saved to input directory\n",
    "\n",
    "    pcd = o3d.io.read_point_cloud(str(pcd_path)) # read the pcd file\n",
    "    # note: by default, o3d.io.write_point_cloud() can create ply files, but the header is incompatible\n",
    "    # with the L1-skeleton software, since o3d defines `property double x`, whereas L1 expects `property float x`, etc\n",
    "    pts = np.asarray(pcd.points)\n",
    "    norms = np.asarray(pcd.normals)\n",
    "    with open(str(output_path), 'w') as h:\n",
    "        h.write(\"ply\\n\")\n",
    "        h.write(\"format ascii 1.0\\n\")\n",
    "        h.write(f\"element vertex {len(pcd.points)}\\n\")\n",
    "        h.write(\"property float x\\n\")\n",
    "        h.write(\"property float y\\n\")\n",
    "        h.write(\"property float z\\n\")\n",
    "        h.write(\"property float nx\\n\")\n",
    "        h.write(\"property float ny\\n\")\n",
    "        h.write(\"property float nz\\n\")\n",
    "        h.write(\"end_header\\n\")\n",
    "        for point, norm in zip(pts, norms):\n",
    "            h.write(f\"{point[0]} {point[1]} {point[2]} {norm[0]} {norm[1]} {norm[2]}\\n\")\n",
    "            \n",
    "def PCD_to_NPY(input_path):\n",
    "    '''Convert .pcd point cloud files to binary .npy format.'''\n",
    "    pcd_path = Path(input_path).expanduser().resolve()\n",
    "    pcd_name = str(pcd_path.stem)\n",
    "    output_path = pcd_path.with_suffix(\".npy\") # by default, output saved to input directory\n",
    "    \n",
    "    pcd = o3d.io.read_point_cloud(str(pcd_path)) # read the pcd file\n",
    "    pts = np.asarray(pcd.points)\n",
    "    np.save(str(output_path), pts)\n",
    "    \n",
    "def XYZ_to_PCD(input_path):\n",
    "    '''Convert .xyz point cloud files to binary .pcd format.'''\n",
    "    xyz_path = Path(input_path).expanduser().resolve()\n",
    "    xyz_name = str(xyz_path.stem)\n",
    "    output_path = xyz_path.with_suffix(\".pcd\") # by default, output saved to input directory\n",
    "    \n",
    "    xyz = o3d.io.read_point_cloud(str(xyz_path)) # read the xyz file\n",
    "    o3d.io.write_point_cloud(str(output_path), xyz)\n",
    "    \n",
    "def read_fork(input_path):\n",
    "    '''Read fork .txt files (of format: x,y,z,nx,ny,nz), and convert to ASCII .ply format.'''\n",
    "    fork_path = Path(input_path).expanduser().resolve()\n",
    "    fork_name = str(fork_path.stem)\n",
    "    output_path = fork_path.with_suffix(\".ply\") # by default, output saved to input directory\n",
    "    \n",
    "    pts = []\n",
    "    norms = []\n",
    "    with open(str(fork_path), 'r') as h:\n",
    "        for line in h:\n",
    "            data = line.split(\",\")\n",
    "            x = data[0].strip()\n",
    "            y = data[1].strip()\n",
    "            z = data[2].strip() # skip null 4th dimension\n",
    "            nx = data[4].strip()\n",
    "            ny = data[5].strip()\n",
    "            nz = data[6].strip(\"\\n\").strip() # has trailing \\n\n",
    "            pts.append([float(x), float(y), float(z)])\n",
    "            norms.append([float(nx), float(ny), float(nz)])\n",
    "    \n",
    "    with open(str(output_path), 'w') as h:\n",
    "        h.write(\"ply\\n\")\n",
    "        h.write(\"format ascii 1.0\\n\")\n",
    "        h.write(f\"element vertex {len(pts)}\\n\")\n",
    "        h.write(\"property float x\\n\")\n",
    "        h.write(\"property float y\\n\")\n",
    "        h.write(\"property float z\\n\")\n",
    "        h.write(\"property float nx\\n\")\n",
    "        h.write(\"property float ny\\n\")\n",
    "        h.write(\"property float nz\\n\")\n",
    "        h.write(\"end_header\\n\")\n",
    "        for point, norm in zip(pts, norms):\n",
    "            h.write(f\"{point[0]} {point[1]} {point[2]} {norm[0]} {norm[1]} {norm[2]}\\n\")\n",
    "            \n",
    "def PLY_to_PCD(input_path):\n",
    "    '''Convert .ply files to binary .pcd format.'''\n",
    "    ply_path = Path(input_path).expanduser().resolve()\n",
    "    ply_name = str(ply_path.stem)\n",
    "    output_path = ply_path.with_suffix(\".pcd\") # by default, output saved to input directory\n",
    "    \n",
    "    ply = o3d.io.read_point_cloud(str(ply_path)) # read the ply file\n",
    "    o3d.io.write_point_cloud(str(output_path), ply)\n",
    "    \n",
    "def make_torus(n, p):\n",
    "    '''Generate n points of a torus, with probability p of missing data.'''\n",
    "    R = 5 # major radius\n",
    "    r = 1 # minor radius\n",
    "    \n",
    "    if p == 0:\n",
    "        suffix = '0'\n",
    "    else:\n",
    "        suffix = str(p).split('.')[1]\n",
    "        if len(suffix) == 1:\n",
    "            suffix = suffix + '0'\n",
    "    \n",
    "    dest = f\"/Users/kianfaizi/Desktop/P3D/Torus/torus{n}_noise{suffix}.xyz\"\n",
    "    \n",
    "#     fig = plt.figure(figsize=(12,12))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    with open(dest, 'w') as h:\n",
    "        for i in range(n):\n",
    "            if random.random() < (1-p): # noise\n",
    "                u = random.uniform(0,360)\n",
    "                v = random.uniform(0,360)\n",
    "                x = (R + r*math.cos(v))*math.cos(u)\n",
    "                y = (R + r*math.cos(v))*math.sin(u)\n",
    "                z = r*math.sin(v)   \n",
    "                h.write(f\"{x} {y} {z}\\n\")\n",
    "                #ax.scatter(x, y, z)\n",
    "\n",
    "    XYZ_to_PCD(dest)\n",
    "    \n",
    "def parse_mat(input_path):\n",
    "    '''Read .mat skeleton files from Cao et al.'''\n",
    "    mat_path = Path(input_path).expanduser().resolve()\n",
    "    mat_name = str(mat_path.stem)\n",
    "    output_path = Path(mat_path.parent, mat_name+\"_laplacian.txt\")\n",
    "    \n",
    "    mat = scipy.io.loadmat(str(mat_path))\n",
    "    mat = (mat['P'])[-1][-1] # discard annotations\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # add skeleton point coordinates\n",
    "    for point in enumerate(mat[-3]):\n",
    "        n = point[0]\n",
    "        coords = point[1]\n",
    "        if not np.isnan(coords[0]):\n",
    "            G.add_node(n, pos=(coords[0], coords[1], coords[2]))\n",
    "\n",
    "    # add edges based on adjacency matrix\n",
    "    adj = pd.DataFrame(mat[-1])\n",
    "    for i in range(adj.shape[0]): # rows\n",
    "        for j in range(i+1, adj.shape[1]): # upper triangular cols\n",
    "            if adj.iloc[i,j] == 1:\n",
    "                G.add_edge(adj.index.values[i], adj.columns.values[j])\n",
    "\n",
    "    # check that all nodes are connected (no gaps in skeleton)\n",
    "    print(f\"Connected components: {len(list(nx.connected_components(G)))}\")\n",
    "    print(f\"Is tree: {nx.is_tree(G)}\")\n",
    "    \n",
    "    make_file(G, output_path)\n",
    "    \n",
    "def parse_skel(input_path):\n",
    "    '''Read .skel skeleton files from Huang et al.'''\n",
    "    skel_path = Path(input_path).expanduser().resolve()\n",
    "    skel_name = str(skel_path.stem)\n",
    "    output_path = Path(skel_path.parent, skel_name+\"_L1\").with_suffix(\".txt\")\n",
    "    \n",
    "    with open(str(skel_path), 'r') as h:\n",
    "        num_on = int(h.readline().split()[1])\n",
    "        # skip ON section (input points/normals)\n",
    "        for i in range(num_on+1):\n",
    "            h.readline()\n",
    "        \n",
    "        # skip SN section (skeleton points before processing?)\n",
    "        num_sn = int(h.readline().split()[1])\n",
    "        for i in range(num_sn+1):\n",
    "            h.readline()\n",
    "        \n",
    "        # CN section contains skeleton branches\n",
    "        # seems like they are written in hierarchical order\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        num_cn = int(h.readline().split()[1])\n",
    "        branches = []\n",
    "        idx = 0 # node ids\n",
    "        pt_ids = {} # node id mappings for graph\n",
    "        \n",
    "        for cnn in range(num_cn):\n",
    "            num_cnn = int(h.readline().split()[1])\n",
    "            pts = [] # ordering/hierarchy\n",
    "            for i in range(num_cnn):\n",
    "                pt = h.readline()\n",
    "                if pt not in pt_ids.keys(): \n",
    "                    pt_ids[pt] = idx\n",
    "                    idx += 1\n",
    "                pts.append(pt)\n",
    "            branches.append(pts)\n",
    "\n",
    "        # add nodes\n",
    "        for pt,idx in pt_ids.items():\n",
    "            coords = (pt.strip('\\n')).split('\\t')\n",
    "            G.add_node(idx, pos=(float(coords[0]), float(coords[1]), float(coords[2])))\n",
    "        \n",
    "        # add edges\n",
    "        for branch in branches:\n",
    "            for i in range(len(branch)-1):\n",
    "                G.add_edge(pt_ids[branch[i]], pt_ids[branch[i+1]])\n",
    "            \n",
    "    # check that all nodes are connected (no gaps in skeleton)\n",
    "    print(f\"Connected components: {len(list(nx.connected_components(G)))}\")\n",
    "    print(f\"Is tree: {nx.is_tree(G)}\")\n",
    "    \n",
    "    make_file(G, output_path)\n",
    "    \n",
    "def parse_txt(input_path):\n",
    "    '''Read .txt files I produced from MarcSchotman's implementation of SkelTree.'''\n",
    "    txt_path = Path(input_path).expanduser().resolve()\n",
    "    txt_name = str(txt_path.stem)\n",
    "    output_path = Path(txt_path.parent, txt_name+\"_skeltree\").with_suffix(\".txt\")\n",
    "    \n",
    "    with open(str(txt_path), 'r') as h:\n",
    "        G = nx.Graph()\n",
    "        connections = {}\n",
    "        for line in h:\n",
    "            # split into: name, coords, neighbors\n",
    "            info = line.strip(\"\\n\").split(\"\\t\")\n",
    "            coords = info[1].strip(\"[]\").split()\n",
    "            coords = list(map(float, coords))\n",
    "            G.add_node(info[0], pos=(coords[0], coords[1], coords[2]))\n",
    "            neighbors = info[2].lstrip(\"dict_keys\").strip(\"()[]\").split(\", \")\n",
    "            neighbors = list(map(lambda x: x[1:-1], neighbors)) # remove extra quotes\n",
    "            connections[info[0]] = neighbors\n",
    "            \n",
    "    # add edges\n",
    "    for k,v in connections.items():\n",
    "        for i in v:\n",
    "            G.add_edge(k,i)\n",
    "            \n",
    "    # check that all nodes are connected (no gaps in skeleton)\n",
    "    print(f\"Connected components: {len(list(nx.connected_components(G)))}\")\n",
    "    print(f\"Is tree: {nx.is_tree(G)}\")\n",
    "            \n",
    "    make_file(G, output_path)\n",
    "    \n",
    "def make_file(G, output_path):\n",
    "    '''Output skeleton into a P3D-readable file.'''\n",
    "    # view input skeleton\n",
    "    nx.draw_spectral(G, with_labels=True)\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for node in G.nodes():\n",
    "        curr = G.nodes[node]\n",
    "        ax.scatter(curr['pos'][0], curr['pos'][1], curr['pos'][2])\n",
    "\n",
    "    # find terminal nodes\n",
    "    terminal_node_ids = [node for node, degree in G.degree() if degree == 1]\n",
    "    \n",
    "    # which node is the root? pick the one with the smallest y-value\n",
    "    root_y = G.nodes[terminal_node_ids[0]]['pos'][1]\n",
    "    root_id = terminal_node_ids[0]\n",
    "    \n",
    "    for i in terminal_node_ids:\n",
    "        y = G.nodes[i]['pos'][1]\n",
    "        if y < root_y:\n",
    "            root_y = y\n",
    "            root_id = i\n",
    "    \n",
    "    attr_mapping = {k:v['pos'] for k,v in G.nodes.data()} # save mapping of nodes:positions\n",
    "    G = nx.dfs_tree(G, root_id) # convert G into an oriented directed graph, starting at root\n",
    "    nx.set_node_attributes(G, attr_mapping, 'pos') # the conversion loses attr data, so add back\n",
    "\n",
    "    # relabel nodes depth-first\n",
    "    preorder = list(nx.dfs_preorder_nodes(G, root_id))\n",
    "    node_mapping = {v:k for k,v in enumerate(preorder)} # old id:new id\n",
    "    G = nx.relabel_nodes(G, node_mapping, copy=True)\n",
    "    root_id = 0\n",
    "\n",
    "    # list nodes in ascending order, per level\n",
    "    level_orders_dict = nx.single_source_shortest_path_length(G, root_id) # id:level\n",
    "    level_orders = [(v,k) for k,v in level_orders_dict.items()] # (level, id)        \n",
    "    level_orders = sorted(level_orders) # ids ascending within each level\n",
    "        \n",
    "    with open(str(output_path), \"w\") as h:\n",
    "        current_level = -1\n",
    "        for depth, node in level_orders:\n",
    "            if current_level != depth:\n",
    "                current_level = depth\n",
    "                h.write(f\"## Level: {depth}\\n\")\n",
    "                counter = 0\n",
    "            coords = G.nodes[node]['pos']\n",
    "            h.write(f\"{coords[0]} {coords[1]} {coords[2]};\".rstrip(\"\\n\"))\n",
    "            children = sorted(list(G.successors(node))) # ids of children\n",
    "            n = len(children)\n",
    "            if n > 0:\n",
    "                for i in range(n-1):\n",
    "                    h.write(f\" [{level_orders_dict[children[i]]},{counter}]\".rstrip(\"\\n\"))\n",
    "                    counter += 1\n",
    "                h.write(f\" [{level_orders_dict[children[n-1]]},{counter}] \\n\")\n",
    "                counter += 1\n",
    "            else:\n",
    "                h.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
